ggplot(log_res, aes(x)) +
geom_line(aes(y = var0, colour = "Entire data set")) +
geom_line(aes(y = var1, colour = "6 first observations")) +
ylab('Log-likelihood')+xlab('Theta')
bayesian <- l_theta(theta, data$Length)
log_res <-
data.frame(
var0 = log_likelihood,
var1 = log_likelihood1,
var2 = bayesian,
x = theta
)
ggplot(log_res, aes(x)) +
geom_line(aes(y = var0, colour = "Entire data set")) +
geom_line(aes(y = var1, colour = "6 first observations")) +
geom_line(aes(y = var2, colour = "Bayesian")) +
ylab('Log-likelihood')+xlab('Theta')
# Loading data
library("readxl")
require(ggplot2)
#install.packages('kknn', dependencies=TRUE)
data <- read_excel("machines.xlsx")
head(data)
d <- density(data$Length) # returns the density data
plot(d) # plots the results
loglike <- function(theta, vector) {
return (length(vector)*log(theta) - theta*sum(vector))
}
l_theta <- function(theta, vector) {
lambda <- 10
prior <- lambda*exp(-lambda*theta)
return (log(prior) + loglike(theta, vector))
}
theta <- seq(from=0.01, to=5.00, by=0.01)
log_likelihood <- loglike(theta, data$Length)
log_likelihood1 <- loglike(theta, data$Length[0:6])
log_res <-
data.frame(
var0 = log_likelihood,
var1 = log_likelihood1,
x = theta
)
ggplot(log_res, aes(x)) +
geom_line(aes(y = var0, colour = "Entire data set")) +
geom_line(aes(y = var1, colour = "6 first observations")) +
ylab('Log-likelihood')+xlab('Theta')
bayesian <- l_theta(theta, data$Length)
log_res <-
data.frame(
var0 = log_likelihood,
var1 = log_likelihood1,
var2 = bayesian,
x = theta
)
ggplot(log_res, aes(x)) +
geom_line(aes(y = var0, colour = "Entire data set")) +
geom_line(aes(y = var1, colour = "6 first observations")) +
geom_line(aes(y = var2, colour = "Bayesian")) +
ylab('Log-likelihood')+xlab('Theta')
random_nmbrs <- rexp(50, rate = 1.13)
hist(random_nmbrs, border="red", ann=FALSE)
par(new=TRUE)
hist(data$Length, border="blue", ann=FALSE, axes=FALSE)
plot(density(random_nmbrs))
time_index = seq(0, 10, 1)
rand_num <-
data.frame(
var0 = random_nmbrs,
var1 = data$Length,
x = time_index
)
random_nmbrs <- rexp(50, rate = 1.13)
plot(density(random_nmbrs), border="red")
lines(density(data$Length), border="blue")
plot(density(data$Length), border="red")
lines(density(random_nmbrs), border="blue")
hist(density(data$Length), border="red")
random_nmbrs <- rexp(50, rate = 1.13)
hist(density(data$Length), border="red")
hist(data$Length, border="red")
lines(random_nmbrs, border="blue")
random_nmbrs <- rexp(50, rate = 1.13)
random_nmbrs <- rexp(50, rate = 1.13)
random_nmbrs$tag <- "Generated values"
data$Length$tag <- "Original values"
combined <- rbind(random_nmbrs, data$Length)
ggplot(combined, aes(length, fill = tag)) + geom_density(alpha = 0.2)
data$tag <- "Original values"
combined <- rbind(random_nmbrs, data)
random_nmbrs <- rexp(50, rate = 1.13)
orig_vals <- data$Length
random_nmbrs$tag <- "Generated values"
orig_vals$tag <- "Original values"
combined <- rbind(random_nmbrs, orig_vals)
ggplot(combined, aes(length, fill = tag)) + geom_density(alpha = 0.2)
random_nmbrs <- rexp(50, rate = 1.13)
orig_vals <- data$Length
random_nmbrs$tag <- 'Generated values'
orig_vals$tag <- 'Original values'
combined <- rbind(random_nmbrs, orig_vals)
View(combined)
# Loading data
library("readxl")
require(ggplot2)
#install.packages('kknn', dependencies=TRUE)
data <- read_excel("machines.xlsx")
head(data)
d <- density(data$Length) # returns the density data
plot(d) # plots the results
loglike <- function(theta, vector) {
return (length(vector)*log(theta) - theta*sum(vector))
}
l_theta <- function(theta, vector) {
lambda <- 10
prior <- lambda*exp(-lambda*theta)
return (log(prior) + loglike(theta, vector))
}
theta <- seq(from=0.01, to=5.00, by=0.01)
log_likelihood <- loglike(theta, data$Length)
log_likelihood1 <- loglike(theta, data$Length[0:6])
log_res <-
data.frame(
var0 = log_likelihood,
var1 = log_likelihood1,
x = theta
)
ggplot(log_res, aes(x)) +
geom_line(aes(y = var0, colour = "Entire data set")) +
geom_line(aes(y = var1, colour = "6 first observations")) +
ylab('Log-likelihood')+xlab('Theta')
bayesian <- l_theta(theta, data$Length)
log_res <-
data.frame(
var0 = log_likelihood,
var1 = log_likelihood1,
var2 = bayesian,
x = theta
)
ggplot(log_res, aes(x)) +
geom_line(aes(y = var0, colour = "Entire data set")) +
geom_line(aes(y = var1, colour = "6 first observations")) +
geom_line(aes(y = var2, colour = "Bayesian")) +
ylab('Log-likelihood')+xlab('Theta')
random_nmbrs <- rexp(50, rate = 1.13)
orig_vals <- data$Length
random_nmbrs$tag <- 'Generated values'
orig_vals$tag <- 'Original values'
combined <- rbind(random_nmbrs, orig_vals)
ggplot(combined, aes(length, fill = tag)) + geom_density(alpha = 0.2)
View(combined)
View(combined)
random_nmbrs <- data.frame(rexp(50, rate = 1.13))
orig_vals <- data.frame(data$Length)
random_nmbrs$tag <- 'Generated values'
orig_vals$tag <- 'Original values'
combined <- rbind(random_nmbrs, orig_vals)
ggplot(combined, aes(length, fill = tag)) + geom_density(alpha = 0.2)
# Loading data
library("readxl")
require(ggplot2)
#install.packages('kknn', dependencies=TRUE)
data <- read_excel("machines.xlsx")
head(data)
d <- density(data$Length) # returns the density data
plot(d) # plots the results
loglike <- function(theta, vector) {
return (length(vector)*log(theta) - theta*sum(vector))
}
l_theta <- function(theta, vector) {
lambda <- 10
prior <- lambda*exp(-lambda*theta)
return (log(prior) + loglike(theta, vector))
}
theta <- seq(from=0.01, to=5.00, by=0.01)
log_likelihood <- loglike(theta, data$Length)
log_likelihood1 <- loglike(theta, data$Length[0:6])
log_res <-
data.frame(
var0 = log_likelihood,
var1 = log_likelihood1,
x = theta
)
ggplot(log_res, aes(x)) +
geom_line(aes(y = var0, colour = "Entire data set")) +
geom_line(aes(y = var1, colour = "6 first observations")) +
ylab('Log-likelihood')+xlab('Theta')
bayesian <- l_theta(theta, data$Length)
log_res <-
data.frame(
var0 = log_likelihood,
var1 = log_likelihood1,
var2 = bayesian,
x = theta
)
ggplot(log_res, aes(x)) +
geom_line(aes(y = var0, colour = "Entire data set")) +
geom_line(aes(y = var1, colour = "6 first observations")) +
geom_line(aes(y = var2, colour = "Bayesian")) +
ylab('Log-likelihood')+xlab('Theta')
random_nmbrs <- data.frame(rexp(50, rate = 1.13))
orig_vals <- data.frame(data$Length)
random_nmbrs$tag <- 'Generated values'
orig_vals$tag <- 'Original values'
combined <- rbind(random_nmbrs, orig_vals)
random_nmbrs <- data.frame(rexp(50, rate = 1.13))
random_nmbrs <- unname(random_nmbrs)
orig_vals <- data.frame(data$Length)
orig_vals <- unname(orig_vals)
random_nmbrs$tag <- 'Generated values'
orig_vals$tag <- 'Original values'
combined <- rbind(random_nmbrs, orig_vals)
ggplot(combined, aes(length, fill = tag)) + geom_density(alpha = 0.2)
ggplot(combined, aes(50, fill = tag)) + geom_density(alpha = 0.2)
ggplot(combined, aes(1, fill = tag)) + geom_density(alpha = 0.2)
combined$length <- 50
ggplot(combined, aes(length, fill = tag)) + geom_density(alpha = 0.2)
combined$length <- 1
ggplot(combined, aes(length, fill = tag)) + geom_density(alpha = 0.2)
random_nmbrs <- data.frame(rexp(50, rate = 1.13))
orig_vals <- data.frame(data$Length)
plot( random_nmbrs, col=rgb(0,0,1,1/4), xlim=c(0,10))  # first histogram
plot( orig_vals, col=rgb(1,0,0,1/4), xlim=c(0,10), add=T)
random_nmbrs <- rexp(50, rate = 1.13)
orig_vals <- data$Length
plot( random_nmbrs, col=rgb(0,0,1,1/4), xlim=c(0,10))  # first histogram
plot( orig_vals, col=rgb(1,0,0,1/4), xlim=c(0,10), add=T)
plot( hist(random_nmbrs), col=rgb(0,0,1,1/4), xlim=c(0,10))  # first histogram
plot( hist(orig_vals), col=rgb(1,0,0,1/4), xlim=c(0,10), add=T)
random_nmbrs <- rexp(50, rate = 1.13)
orig_vals <- data$Length
plot( hist(random_nmbrs), col=rgb(0,0,1,1/4), xlim=c(0,10))  # first histogram
plot( hist(orig_vals), col=rgb(1,0,0,1/4), xlim=c(0,10), add=T)
plot( hist(orig_vals), col=rgb(0,0,1,1/4), xlim=c(0,10))  # first histogram
plot( hist(random_nmbrs), col=rgb(1,0,0,1/4), xlim=c(0,10), add=T)
orig_vals <- data$Length
plot( hist(orig_vals), col=rgb(0,0,1,1/4), xlim=c(0,10))  # first histogram
plot( hist(random_nmbrs), col=rgb(1,0,0,1/4), xlim=c(0,10), add=T)
p1 <- hist(rnorm(500,4))                     # centered at 4
p2 <- hist(rnorm(500,6))                     # centered at 6
plot( p1, col=rgb(0,0,1,1/4), xlim=c(0,10))  # first histogram
plot( p2, col=rgb(1,0,0,1/4), xlim=c(0,10), add=T)  # second
random_nmbrs <- hist(rexp(50, rate = 1.13))
orig_vals <- hist(data$Length)
plot( orig_vals, col=rgb(0,0,1,1/4), xlim=c(0,10))  # first histogram
plot( random_nmbrs, col=rgb(1,0,0,1/4), xlim=c(0,10), add=T)
plot( random_nmbrs, col=rgb(0,0,1,1/4), xlim=c(0,10))  # first histogram
plot( orig_vals, col=rgb(1,0,0,1/4), xlim=c(0,10), add=T)
plot( random_nmbrs, col=rgb(0,0,1,1/4), xlim=c(0,6))  # first histogram
plot( orig_vals, col=rgb(1,0,0,1/4), xlim=c(0,6), add=T)
random_nmbrs <- hist(rexp(50, rate = 1.13), plot = FALSE)
orig_vals <- hist(data$Length, plot = FALSE)
plot( random_nmbrs, col=rgb(0,0,1,1/4), xlim=c(0,6))  # first histogram
plot( orig_vals, col=rgb(1,0,0,1/4), xlim=c(0,6), add=T)
plot( random_nmbrs, col=rgb(0,0,1,1/4), xlim=c(0,6))  # first histogram
plot( orig_vals, col=rgb(1,0,0,1/4), xlim=c(0,6), add=T)
plot( random_nmbrs, col=rgb(0,0,1,1/4), xlim=c(0,6))  # first histogram
plot( orig_vals, col=rgb(1,0,0,1/4), xlim=c(0,6), add=T)
?rexp
#install.packages("glmnet", dependencies = TRUE)
library(Metrics)
library(ggplot2)
library(MASS)
library(glmnet)
require(glmnet)
require(glmnet)
require(glmnet)
## PART 1: Load data
library("readxl")
#install.packages("glmnet", dependencies = TRUE)
library(Metrics)
library(ggplot2)
library(MASS)
require(glmnet)
require(glmnet)
## PART 1: Load data
library("readxl")
#install.packages("glmnet", dependencies = TRUE)
library(Metrics)
library(ggplot2)
library(MASS)
require(glmnet)
data <- read_excel("tecator.xlsx")
head(data)
plot(data$Moisture, data$Protein, xlab = "Moisture", ylab = "Protein")
## PART #:
# Split into train & test set
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
test=data[-id,]
## Create models
M1 <- lm(Moisture ~ Protein, data = train )
M2 <- lm(Moisture ~ Protein + I(Protein^2), data = train )
M3 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3), data = train )
M4 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4), data = train )
M5 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4) + I(Protein^5), data = train )
M6 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4) + I(Protein^5) + I(Protein^6), data = train )
# Fit M1
M1.test_preds <- predict(M1, test, type = "response")
M1.train_preds <- predict(M1, train, type = "response")
M1.test_mse <- mse(M1.test_preds, test$Moisture)
M1.train_mse <- mse(M1.train_preds, train$Moisture)
# Fit M2
M2.test_preds <- predict(M2, test, type = "response")
M2.train_preds <- predict(M2, train, type = "response")
M2.test_mse <- mse(M2.test_preds, test$Moisture)
M2.train_mse <- mse(M2.train_preds, train$Moisture)
# Fit M3
M3.test_preds <- predict(M3, test, type = "response")
M3.train_preds <- predict(M3, train, type = "response")
M3.test_mse <- mse(M3.test_preds, test$Moisture)
M3.train_mse <- mse(M3.train_preds, train$Moisture)
# Fit M4
M4.test_preds <- predict(M4, test, type = "response")
M4.train_preds <- predict(M4, train, type = "response")
M4.test_mse <- mse(M4.test_preds, test$Moisture)
M4.train_mse <- mse(M4.train_preds, train$Moisture)
# Fit M5
M5.test_preds <- predict(M5, test, type = "response")
M5.train_preds <- predict(M5, train, type = "response")
M5.test_mse <- mse(M5.test_preds, test$Moisture)
M5.train_mse <- mse(M5.train_preds, train$Moisture)
# Fit M6
M6.test_preds <- predict(M6, test, type = "response")
M6.train_preds <- predict(M6, train, type = "response")
M6.test_mse <- mse(M6.test_preds, test$Moisture)
M6.train_mse <- mse(M6.train_preds, train$Moisture)
MSE.test<- c(M1.test_mse,M2.test_mse, M3.test_mse, M4.test_mse, M5.test_mse, M6.test_mse)
MSE.train<- c(M1.train_mse,M2.train_mse, M3.train_mse, M4.train_mse, M5.train_mse, M6.train_mse)
x <- seq(1, 6, by=1)
MSE_res <-
data.frame(
var0 = MSE.test,
var1 = MSE.train,
x = x
)
ggplot(MSE_res, aes(x)) +
geom_line(aes(y = var0, colour = "Test")) +
geom_line(aes(y = var1, colour = "Train")) +
ylab('MSE')+xlab('I')
## Create models
M1 <- lm(Moisture ~ Protein, data = train )
M2 <- lm(Moisture ~ Protein + I(Protein^2), data = train )
M3 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3), data = train )
M4 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4), data = train )
M5 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4) + I(Protein^5), data = train )
M6 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4) + I(Protein^5) + I(Protein^6), data = train )
# Fit M1
M1.test_preds <- predict(M1, test, type = "response")
mean((test$Moisture - M1.test_preds)^2)
mse(M1.test_preds, test$Moisture)
mean((M1.test_preds - test$Moisture)^2)
## Create models
M1 <- lm(Moisture ~ Protein, data = train )
M2 <- lm(Moisture ~ Protein + I(Protein^2), data = train )
M3 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3), data = train )
M4 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4), data = train )
M5 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4) + I(Protein^5), data = train )
M6 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4) + I(Protein^5) + I(Protein^6), data = train )
# Predict M1
M1.test_preds <- predict(M1, test, type = "response")
M1.train_preds <- predict(M1, train, type = "response")
M1.test_mse <- mean((M1.test_preds - test$Moisture)^2)
M1.train_mse <- mean((M1.train_preds - train$Moisture)^2)
# Predict M2
M2.test_preds <- predict(M2, test, type = "response")
M2.train_preds <- predict(M2, train, type = "response")
M2.test_mse <- mean((M2.test_preds - test$Moisture)^2)
M2.train_mse <- mean((M2.train_preds - train$Moisture)^2)
# Predict M3
M3.test_preds <- predict(M3, test, type = "response")
M3.train_preds <- predict(M3, train, type = "response")
M3.test_mse <- mean((M3.test_preds - test$Moisture)^2)
M3.train_mse <- mean((M3.train_preds - train$Moisture)^2)
# Predict M4
M4.test_preds <- predict(M4, test, type = "response")
M4.train_preds <- predict(M4, train, type = "response")
M4.test_mse <- mean((M4.test_preds - test$Moisture)^2)
M4.train_mse <- mean((M4.train_preds - train$Moisture)^2)
# Predict M5
M5.test_preds <- predict(M5, test, type = "response")
M5.train_preds <- predict(M5, train, type = "response")
M5.test_mse <- mean((M5.test_preds - test$Moisture)^2)
M5.train_mse <- mean((M5.train_preds - train$Moisture)^2)
# Predict M6
M6.test_preds <- predict(M6, test, type = "response")
M6.train_preds <- predict(M6, train, type = "response")
M6.test_mse <- mean((M6.test_preds - test$Moisture)^2)
M6.train_mse <- mean((M6.train_preds - train$Moisture)^2)
MSE.test<- c(M1.test_mse,M2.test_mse, M3.test_mse, M4.test_mse, M5.test_mse, M6.test_mse)
MSE.train<- c(M1.train_mse,M2.train_mse, M3.train_mse, M4.train_mse, M5.train_mse, M6.train_mse)
x <- seq(1, 6, by=1)
MSE_res <-
data.frame(
var0 = MSE.test,
var1 = MSE.train,
x = x
)
ggplot(MSE_res, aes(x)) +
geom_line(aes(y = var0, colour = "Test")) +
geom_line(aes(y = var1, colour = "Train")) +
ylab('MSE')+xlab('I')
## Part 4
linearModel <- lm(Fat ~ . - Protein - Moisture - Sample, data = train )
aic <- stepAIC(linearModel)
aic$anova$Step
## Part 4
linearModel <- lm(Fat ~ . - Protein - Moisture - Sample, data = data )
aic <- stepAIC(linearModel)
aic$anova$Step
## Part 4
linearModel <- lm(Fat ~ . - Protein - Moisture - Sample, data = data )
aic <- stepAIC(linearModel)
aic$anova
summary(step)
summary(aic)
aic$anova$Step
aic$anova
?lm
View(aic)
View(aic)
summary(aic$anova)
?glmnet
fit.ridge=glmnet(x,data$Fat,alpha=0, family="gaussian")
plot(fit.ridge,xvar="lambda",label=TRUE)
## PART 1: Load data
library("readxl")
#install.packages("glmnet", dependencies = TRUE)
library(Metrics)
library(ggplot2)
library(MASS)
require(glmnet)
data <- read_excel("tecator.xlsx")
head(data)
plot(data$Moisture, data$Protein, xlab = "Moisture", ylab = "Protein")
## PART #:
# Split into train & test set
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
test=data[-id,]
## Create models
M1 <- lm(Moisture ~ Protein, data = train )
M2 <- lm(Moisture ~ Protein + I(Protein^2), data = train )
M3 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3), data = train )
M4 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4), data = train )
M5 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4) + I(Protein^5), data = train )
M6 <- lm(Moisture ~ Protein + I(Protein^2) + I(Protein^3) + I(Protein^4) + I(Protein^5) + I(Protein^6), data = train )
# Predict M1
M1.test_preds <- predict(M1, test, type = "response")
M1.train_preds <- predict(M1, train, type = "response")
M1.test_mse <- mean((M1.test_preds - test$Moisture)^2)
M1.train_mse <- mean((M1.train_preds - train$Moisture)^2)
# Predict M2
M2.test_preds <- predict(M2, test, type = "response")
M2.train_preds <- predict(M2, train, type = "response")
M2.test_mse <- mean((M2.test_preds - test$Moisture)^2)
M2.train_mse <- mean((M2.train_preds - train$Moisture)^2)
# Predict M3
M3.test_preds <- predict(M3, test, type = "response")
M3.train_preds <- predict(M3, train, type = "response")
M3.test_mse <- mean((M3.test_preds - test$Moisture)^2)
M3.train_mse <- mean((M3.train_preds - train$Moisture)^2)
# Predict M4
M4.test_preds <- predict(M4, test, type = "response")
M4.train_preds <- predict(M4, train, type = "response")
M4.test_mse <- mean((M4.test_preds - test$Moisture)^2)
M4.train_mse <- mean((M4.train_preds - train$Moisture)^2)
# Predict M5
M5.test_preds <- predict(M5, test, type = "response")
M5.train_preds <- predict(M5, train, type = "response")
M5.test_mse <- mean((M5.test_preds - test$Moisture)^2)
M5.train_mse <- mean((M5.train_preds - train$Moisture)^2)
# Predict M6
M6.test_preds <- predict(M6, test, type = "response")
M6.train_preds <- predict(M6, train, type = "response")
M6.test_mse <- mean((M6.test_preds - test$Moisture)^2)
M6.train_mse <- mean((M6.train_preds - train$Moisture)^2)
MSE.test<- c(M1.test_mse,M2.test_mse, M3.test_mse, M4.test_mse, M5.test_mse, M6.test_mse)
MSE.train<- c(M1.train_mse,M2.train_mse, M3.train_mse, M4.train_mse, M5.train_mse, M6.train_mse)
x <- seq(1, 6, by=1)
MSE_res <-
data.frame(
var0 = MSE.test,
var1 = MSE.train,
x = x
)
ggplot(MSE_res, aes(x)) +
geom_line(aes(y = var0, colour = "Test")) +
geom_line(aes(y = var1, colour = "Train")) +
ylab('MSE')+xlab('i')
## Part 4
linearModel <- lm(Fat ~ . - Protein - Moisture - Sample, data = data )
aic <- stepAIC(linearModel)
summary(aic$anova)
x=model.matrix(Fat~. - Protein - Moisture - Sample,data=data)
fit.ridge=glmnet(x,data$Fat,alpha=0, family="gaussian")
plot(fit.ridge,xvar="lambda",label=TRUE)
fit.ridge=glmnet(x,data$Fat,alpha=0)
plot(fit.ridge,xvar="lambda",label=TRUE)
fit.lasso=glmnet(x,data$Fat,alpha=1)
plot(fit.lasso,xvar="lambda",label=TRUE)
fit.lasso=glmnet(x,data$Fat,alpha=1, family="gaussian")
plot(fit.lasso,xvar="lambda",label=TRUE)
cv.lasso=cv.glmnet(x,data$Fat, alpha=1, family="gaussian")
cv.lasso$lambda.min
cv.lasso=cv.glmnet(x,data$Fat, alpha=1)
cv.lasso$lambda.min
fit.ridge=glmnet(x,data$Fat,alpha=0)
plot(fit.ridge,xvar="lambda",label=TRUE)
